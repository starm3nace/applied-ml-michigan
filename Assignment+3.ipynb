{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 3, question 5 code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(X_test))\n",
    "print(m)\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "y_predicted = m.predict(X_test)\n",
    "print(\"y_predicted.shape: {}\".format(y_predicted.shape))\n",
    "print(\"y_test.shape: {}\".format(y_test.shape))\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_scores = m.decision_function(X_test)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "prec_vs_rec = list(zip(precision, recall))\n",
    "\n",
    "#print(('precision', 'recall'))\n",
    "#for s in prec_vs_rec:\n",
    "#  print(s)\n",
    "#print(recall)\n",
    "print(np.argmin(recall > 0.8))\n",
    "\n",
    "ix_below = np.argmin(recall > 0.8)\n",
    "ix_above = ix_below - 1\n",
    "\n",
    "print(ix_above, ix_below)\n",
    "\n",
    "print('Closest recalls: {}'.format(recall[[ix_above, ix_below]]))\n",
    "print('Closest prec-ns: {}'.format(precision[[ix_above, ix_below]]))\n",
    "print('Approximate prec-n: {}'.format((precision[[ix_above, ix_below]].mean())))\n",
    "\n",
    "print(\"the end\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8\n",
    "print(m)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "\n",
    "m_predicted = m.predict(X_test)\n",
    "\n",
    "\n",
    "print('Macro-averaged precision = {:.2f} (treat classes equally)'\n",
    "      .format(precision_score(y_test, m_predicted, average = 'macro')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q13\n",
    "\n",
    "print(m)\n",
    "\n",
    "param_range = [0.01, 0.1, 1, 10]\n",
    "grid_values = {'gamma': param_range,\n",
    "               'c': param_range}\n",
    "\n",
    "print(grid_values)\n",
    "\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "# alternative metric to optimize over grid parameters: recall\n",
    "\n",
    "#gs = GridSearchCV(m, param_grid = grid_values, scoring = 'recall')\n",
    "gs = GridSearchCV(m, param_grid = grid_values, scoring = 'roc_auc')\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs)\n",
    "\n",
    "print(type(gs))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Evaluation\n",
    "\n",
    "In this assignment you will train several models and evaluate how effectively they predict instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud).\n",
    " \n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Import the data from `fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
    "\n",
    "*This function should return a float between 0 and 1.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016410823768035772"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "    # Your code here\n",
    "    df = pd.read_csv('fraud_data.csv')\n",
    "    fraud_share = df['Class'].sum()/len(df['Class'])\n",
    "    return fraud_share\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('fraud_data.csv')\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
    "\n",
    "*This function should a return a tuple with two floats, i.e. `(accuracy score, recall score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98525073746312686, 0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    from sklearn.metrics import accuracy_score, recall_score\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "    # Negative class (0) is most frequent\n",
    "    dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "    # Therefore the dummy 'most_frequent' classifier always predicts class 0\n",
    "    y_dummy_predictions = dummy_majority.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    accuracy = accuracy_score(y_test, y_dummy_predictions)\n",
    "    recall = recall_score(y_test, y_dummy_predictions)\n",
    "\n",
    "    return (accuracy, recall)# Return your answer\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n",
    "\n",
    "*This function should a return a tuple with three floats, i.e. `(accuracy score, recall score, precision score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99078171091445433, 0.375, 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    from sklearn.metrics import recall_score, precision_score\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    # Your code here\n",
    "    svm = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "    #svm.score(X_test, y_test)\n",
    "    return (svm.score(X_test, y_test),\n",
    "            recall_score(y_test, svm.predict(X_test)),\n",
    "            precision_score(y_test, svm.predict(X_test)))\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Using the SVC classifier with parameters `{'C': 1e9, 'gamma': 1e-07}`, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test and y_test.\n",
    "\n",
    "*This function should return a confusion matrix, a 2x2 numpy array with 4 integers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5320,   24],\n",
       "       [  14,   66]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    # Your code here\n",
    "    params = {\n",
    "              'C': 1e9,\n",
    "              'gamma': 1e-07\n",
    "             }\n",
    "\n",
    "    svm = SVC(**params).fit(X_train, y_train)\n",
    "\n",
    "    svm_decisions = svm.decision_function(X_test)\n",
    "    threshold = -220\n",
    "    y_predicted = (svm_decisions > threshold)\n",
    "    return confusion_matrix(y_true=y_test, y_pred=y_predicted)\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Train a logisitic regression classifier with default parameters using X_train and y_train.\n",
    "\n",
    "For the logisitic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
    "\n",
    "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
    "\n",
    "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?\n",
    "\n",
    "*This function should return a tuple with two floats, i.e. `(recall, true positive rate)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82499999999999996, 0.9375)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "        \n",
    "    # Your code here\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    lr = LogisticRegression().fit(X_train, y_train)\n",
    "    lr_predicted = lr.predict(X_test)\n",
    "    y_score_lr = lr.decision_function(X_test)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_score_lr)\n",
    "    # Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
    "\n",
    "    r1 = recall[np.abs(precision-0.75).argmin()]\n",
    "\n",
    "\n",
    "    from sklearn.metrics import roc_curve\n",
    "\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_lr)\n",
    "\n",
    "    tpr1 = tpr_lr[np.abs(fpr_lr-0.16).argmin()]\n",
    "\n",
    "    return (r1, tpr1)\n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
    "\n",
    "`'penalty': ['l1', 'l2']`\n",
    "\n",
    "`'C':[0.01, 0.1, 1, 10, 100]`\n",
    "\n",
    "From `.cv_results_`, create an array of the mean test scores of each parameter combination. i.e.\n",
    "\n",
    "|      \t| `l1` \t| `l2` \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| **`0.01`** \t|    ?\t|   ? \t|\n",
    "| **`0.1`**  \t|    ?\t|   ? \t|\n",
    "| **`1`**    \t|    ?\t|   ? \t|\n",
    "| **`10`**   \t|    ?\t|   ? \t|\n",
    "| **`100`**   \t|    ?\t|   ? \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "*This function should return a 5 by 2 numpy array with 10 floats.* \n",
    "\n",
    "*Note: do not return a DataFrame, just the values denoted by '?' above in a numpy array.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66666667,  0.76086957],\n",
       "       [ 0.80072464,  0.80434783],\n",
       "       [ 0.8115942 ,  0.8115942 ],\n",
       "       [ 0.80797101,  0.8115942 ],\n",
       "       [ 0.80797101,  0.80797101]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():    \n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    # Your code here\n",
    "    lr = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    grid_values = {'C':[0.01, 0.1, 1, 10, 100],\n",
    "                    'penalty':['l1', 'l2']}\n",
    "\n",
    "    gs = GridSearchCV(lr,\n",
    "                      param_grid = grid_values,\n",
    "                      cv=3,\n",
    "                      scoring='recall'\n",
    "                     )\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    #gs.cv_results_['params']\n",
    "    #gs.cv_results_['mean_test_score']\n",
    "    return gs.cv_results_['mean_test_score'].reshape(5, 2)\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58c96c0c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the following function to help visualize results from the grid search\n",
    "def GridSearch_Heatmap(scores):\n",
    "    %matplotlib inline\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    sns.heatmap(scores, xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])\n",
    "    plt.yticks(rotation=0);\n",
    "\n",
    "#GridSearch_Heatmap(answer_six())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
